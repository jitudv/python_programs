theme(axis.text.x = element_text(angle = 90, hjust = 1))
ggplot(df, aes(x = Var1, y = Freq)) +
geom_bar(stat = "identity", color = "black", fill = "grey") +
labs(title = "Frequency by Artist Nationality\n", x = "\nCountry", y = "Frequency\n") +
theme_classic() +
theme(axis.text.x = element_text(angle = 90, hjust = 1))
city <- data.frame(table(met.collection$City))
city <- city[order(city$Freq,-rank(city$Freq), decreasing = TRUE), ]
View(city)
df <- city[2:11, ]
ggplot(df, aes(x = Var1, y = Freq)) +
geom_bar(stat = "identity", color = "black", fill = "grey") +
labs(title = "Frequency by Artist Nationality\n", x = "\nCountry", y = "Frequency\n") +
theme_classic() +
theme(axis.text.x = element_text(angle = 90, hjust = 1))
df <- city[2:11, ]
ggplot(df, aes(x = Var1, y = Freq)) +
geom_bar(stat = "identity", color = "black", fill = "grey") +
labs(title = "Frequency by City\n", x = "\nCountry", y = "Frequency\n") +
theme_classic() +
theme(axis.text.x = element_text(angle = 90, hjust = 1))
artist <- data.frame(table(met.collection$Artist.Name))
artist <- artist[order(artist$Freq,-rank(artist$Freq), decreasing = TRUE), ]
df <- artist[2:11, ]
ggplot(df, aes(x = Var1, y = Freq)) +
geom_bar(stat = "identity", color = "black", fill = "grey") +
labs(title = "Frequency by artist\n", x = "\nCountry", y = "Frequency\n") +
theme_classic() +
theme(axis.text.x = element_text(angle = 90, hjust = 1))
artist <- data.frame(table(met.collection$Artist.Name))
artist <- artist[order(artist$Freq,-rank(artist$Freq), decreasing = TRUE), ]
artist <- data.frame(table(met.collection$Artist.Display.Name))
artist <- data.frame(table(met.collection$Artist.Display.Name))
artist <- artist[order(artist$Freq,-rank(artist$Freq), decreasing = TRUE), ]
df <- artist[2:11, ]
ggplot(df, aes(x = Var1, y = Freq)) +
geom_bar(stat = "identity", color = "black", fill = "grey") +
labs(title = "Frequency by artist\n", x = "\nCountry", y = "Frequency\n") +
theme_classic() +
theme(axis.text.x = element_text(angle = 90, hjust = 1))
df <- artist[2:21, ]
ggplot(df, aes(x = Var1, y = Freq)) +
geom_bar(stat = "identity", color = "black", fill = "grey") +
labs(title = "Frequency by artist\n", x = "\nCountry", y = "Frequency\n") +
theme_classic() +
theme(axis.text.x = element_text(angle = 90, hjust = 1))
artist <- data.frame(table(met.collection$Metadata.Date))
artist <- artist[order(artist$Freq,-rank(artist$Freq), decreasing = TRUE), ]
df <- artist[2:21, ]
ggplot(df, aes(x = Var1, y = Freq)) +
geom_bar(stat = "identity", color = "black", fill = "grey") +
labs(title = "Frequency by artist\n", x = "\nCountry", y = "Frequency\n") +
theme_classic() +
theme(axis.text.x = element_text(angle = 90, hjust = 1))
artist <- artist[order(artist$Freq,-rank(artist$Freq), decreasing = TRUE), ]
View(artist)
artist <- data.frame(table(met.collection$Period))
artist <- artist[order(artist$Freq,-rank(artist$Freq), decreasing = TRUE), ]
df <- artist[2:21, ]
ggplot(df, aes(x = Var1, y = Freq)) +
geom_bar(stat = "identity", color = "black", fill = "grey") +
labs(title = "Frequency by artist\n", x = "\nCountry", y = "Frequency\n") +
theme_classic() +
theme(axis.text.x = element_text(angle = 90, hjust = 1))
period <- data.frame(table(met.collection$Period))
period <- period[order(period$Freq,-rank(period$Freq), decreasing = TRUE), ]
df <- period[2:11, ]
ggplot(df, aes(x = Var1, y = Freq)) +
geom_bar(stat = "identity", color = "black", fill = "grey") +
labs(title = "Frequency by period\n", x = "\nCountry", y = "Frequency\n") +
theme_classic() +
theme(axis.text.x = element_text(angle = 90, hjust = 1))
View(met.collection)
summary(met.collection$Object.Date)
period <- data.frame(table(met.collection$Object.Date))
period <- period[order(period$Freq,-rank(period$Freq), decreasing = TRUE), ]
df <- period[2:11, ]
ggplot(df, aes(x = Var1, y = Freq)) +
geom_bar(stat = "identity", color = "black", fill = "grey") +
labs(title = "Frequency by period\n", x = "\nCountry", y = "Frequency\n") +
theme_classic() +
theme(axis.text.x = element_text(angle = 90, hjust = 1))
df <- period[3:11, ]
ggplot(df, aes(x = Var1, y = Freq)) +
geom_bar(stat = "identity", color = "black", fill = "grey") +
labs(title = "Frequency by period\n", x = "\nCountry", y = "Frequency\n") +
theme_classic() +
theme(axis.text.x = element_text(angle = 90, hjust = 1))
df <- period[3:11, ]
ggplot(df, aes(x = Var1, y = -Freq)) +
geom_bar(stat = "identity", color = "black", fill = "grey") +
labs(title = "Frequency by period\n", x = "\nCountry", y = "Frequency\n") +
theme_classic() +
theme(axis.text.x = element_text(angle = 90, hjust = 1))
df <- period[3:11, ]
ggplot(df, aes(x = -Var1, y = Freq)) +
geom_bar(stat = "identity", color = "black", fill = "grey") +
labs(title = "Frequency by period\n", x = "\nCountry", y = "Frequency\n") +
theme_classic() +
theme(axis.text.x = element_text(angle = 90, hjust = 1))
ggplot(df, aes(x = Var1, y = order(rank(-Freq))) +
geom_bar(stat = "identity", color = "black", fill = "grey") +
labs(title = "Frequency by period\n", x = "\nCountry", y = "Frequency\n") +
theme_classic() +
theme(axis.text.x = element_text(angle = 90, hjust = 1))
][[s]]
date <- data.frame(table(met.collection$Object.Date))
date <- date[order(date$Freq,-rank(date$Freq), decreasing = TRUE), ]
df <- date[3:11, ]
ggplot(df, aes(x = Var1, y = Freq)) +
geom_bar(stat = "identity", color = "black", fill = "grey") +
labs(title = "Frequency by Date\n", x = "\nCountry", y = "Frequency\n") +
theme_classic() +
theme(axis.text.x = element_text(angle = 90, hjust = 1))
library("kernlab")
install.packages("kernlab")
install.packages("caret")
setwd("~/GitHub/1k-classifier/data")
corpus1 <- VCorpus(DirSource("Like", encoding = "UTF-8"), readerControl=list(language="English"))
#clean your data
corpus1 <- tm_map(corpus1, content_transformer(stripWhitespace))
corpus1 <- tm_map(corpus1, content_transformer(tolower))
corpus1 <- tm_map(corpus1, content_transformer(removeNumbers))
# corpus1 <- tm_map(corpus1, removeWords, stopwords("English")) ## inspect your stopword lists
corpus1 <- tm_map(corpus1, content_transformer(removePunctuation))
# corpus1 <- tm_map(corpus1, stemDocument, language = "english") # stem your words
#create your document term matrix
corpus1.dtm<-DocumentTermMatrix(corpus1, control=list(wordLengths=c(1,Inf)))
corpus1.matrix<-as.matrix(corpus1.dtm, stringsAsFactors=F)
corpus1 <- VCorpus(DirSource("Like", encoding = "UTF-8"), readerControl=list(language="English"))
library("kernlab")
library("caret")
library("tm")
library("SnowballC")
library("splitstackshape")
corpus1 <- VCorpus(DirSource("Like", encoding = "UTF-8"), readerControl=list(language="English"))
#clean your data
corpus1 <- tm_map(corpus1, content_transformer(stripWhitespace))
corpus1 <- tm_map(corpus1, content_transformer(tolower))
corpus1 <- tm_map(corpus1, content_transformer(removeNumbers))
# corpus1 <- tm_map(corpus1, removeWords, stopwords("English")) ## inspect your stopword lists
corpus1 <- tm_map(corpus1, content_transformer(removePunctuation))
corpus1.dtm<-DocumentTermMatrix(corpus1, control=list(wordLengths=c(1,Inf)))
corpus1.matrix<-as.matrix(corpus1.dtm, stringsAsFactors=F)
folds<-createFolds(df$corpus, k=5) # k = number of folds (1-10) where 10 is best
View(corpus1.matrix)
label.df<-data.frame(row.names(corpus1.scaled))
colnames(label.df)<-c("filenames")
label.df<-cSplit(label.df, 'filenames', sep="_", type.convert=FALSE)
corpus1.scaled<-data.frame(corpus1.scaled)
corpus1.scaled$corpus<-label.df$filenames_1
df<-corpus1.scaled
label.df<-data.frame(row.names(corpus1.matrix))
colnames(label.df)<-c("filenames")
label.df<-cSplit(label.df, 'filenames', sep="_", type.convert=FALSE)
corpus1.scaled<-data.frame(corpus1.scaled)
corpus1.scaled$corpus<-label.df$filenames_1
df<-corpus1.scaled
label.df<-data.frame(row.names(corpus1.matrix))
colnames(label.df)<-c("filenames")
label.df<-cSplit(label.df, 'filenames', sep="_", type.convert=FALSE)
corpus1.scaled<-data.frame(corpus1.matrix)
corpus1.scaled$corpus<-label.df$filenames_1
df<-corpus1.matrix
View(df)
folds<-createFolds(df$corpus, k=5) # k = number of folds (1-10) where 10 is best
View(df)
setwd("~/GitHub/1k-classifier/data")
#Step 1: read in corpus1
corpus1 <- VCorpus(DirSource("Poems_Text", encoding = "UTF-8"), readerControl=list(language="English"))
#clean your data
corpus1 <- tm_map(corpus1, content_transformer(stripWhitespace))
corpus1 <- tm_map(corpus1, content_transformer(tolower))
corpus1 <- tm_map(corpus1, content_transformer(removeNumbers))
# corpus1 <- tm_map(corpus1, removeWords, stopwords("English")) ## inspect your stopword lists
corpus1 <- tm_map(corpus1, content_transformer(removePunctuation))
# corpus1 <- tm_map(corpus1, stemDocument, language = "english") # stem your words
#create your document term matrix
corpus1.dtm<-DocumentTermMatrix(corpus1, control=list(wordLengths=c(1,Inf)))
corpus1.matrix<-as.matrix(corpus1.dtm, stringsAsFactors=F)
#perform transformations on the raw counts
#Remove sparse terms
corpus1.dtm.sparse<-removeSparseTerms(corpus1.dtm, 0.4) #lower number = requiring that a word be in more documents
corpus1.matrix.sparse<-as.matrix(corpus1.dtm.sparse, stringsAsFactors=F)
#Scale your data
scaling1<-rowSums(corpus1.matrix) #get total word counts for each work
corpus1.scaled<-corpus1.matrix.sparse/scaling1
#Label your data
label.df<-data.frame(row.names(corpus1.scaled))
colnames(label.df)<-c("filenames")
label.df<-cSplit(label.df, 'filenames', sep="_", type.convert=FALSE)
corpus1.scaled<-data.frame(corpus1.scaled)
corpus1.scaled$corpus<-label.df$filenames_1
df<-corpus1.scaled
library("kernlab")
library("caret")
library("tm")
library("SnowballC")
library("splitstackshape")
install.packages("splitstackshape")
setwd("~/GitHub/1k-classifier/data")
#Step 1: read in corpus1
corpus1 <- VCorpus(DirSource("Poems_Text", encoding = "UTF-8"), readerControl=list(language="English"))
#clean your data
corpus1 <- tm_map(corpus1, content_transformer(stripWhitespace))
corpus1 <- tm_map(corpus1, content_transformer(tolower))
corpus1 <- tm_map(corpus1, content_transformer(removeNumbers))
# corpus1 <- tm_map(corpus1, removeWords, stopwords("English")) ## inspect your stopword lists
corpus1 <- tm_map(corpus1, content_transformer(removePunctuation))
# corpus1 <- tm_map(corpus1, stemDocument, language = "english") # stem your words
#create your document term matrix
corpus1.dtm<-DocumentTermMatrix(corpus1, control=list(wordLengths=c(1,Inf)))
corpus1.matrix<-as.matrix(corpus1.dtm, stringsAsFactors=F)
#perform transformations on the raw counts
#Remove sparse terms
corpus1.dtm.sparse<-removeSparseTerms(corpus1.dtm, 0.4) #lower number = requiring that a word be in more documents
corpus1.matrix.sparse<-as.matrix(corpus1.dtm.sparse, stringsAsFactors=F)
#Scale your data
scaling1<-rowSums(corpus1.matrix) #get total word counts for each work
corpus1.scaled<-corpus1.matrix.sparse/scaling1
#Label your data
label.df<-data.frame(row.names(corpus1.scaled))
colnames(label.df)<-c("filenames")
label.df<-cSplit(label.df, 'filenames', sep="_", type.convert=FALSE)
corpus1.scaled<-data.frame(corpus1.scaled)
corpus1.scaled$corpus<-label.df$filenames_1
df<-corpus1.scaled
#Step 2: Run classification test using SVM learning algorithm
#first create folds
folds<-createFolds(df$corpus, k=5) # k = number of folds (1-10) where 10 is best
setwd("~/GitHub/1k-classifier/data")
#Step 1: read in corpus1
corpus1 <- VCorpus(DirSource("Poems_Text", encoding = "UTF-8"), readerControl=list(language="English"))
#clean your data
corpus1 <- tm_map(corpus1, content_transformer(stripWhitespace))
corpus1 <- tm_map(corpus1, content_transformer(tolower))
corpus1 <- tm_map(corpus1, content_transformer(removeNumbers))
# corpus1 <- tm_map(corpus1, removeWords, stopwords("English")) ## inspect your stopword lists
corpus1 <- tm_map(corpus1, content_transformer(removePunctuation))
# corpus1 <- tm_map(corpus1, stemDocument, language = "english") # stem your words
setwd("~/GitHub/1k-classifier/data")
corpus1 <- VCorpus(DirSource("Test", encoding = "UTF-8"), readerControl=list(language="English"))
#clean your data
corpus1 <- tm_map(corpus1, content_transformer(stripWhitespace))
corpus1 <- tm_map(corpus1, content_transformer(tolower))
corpus1 <- tm_map(corpus1, content_transformer(removeNumbers))
# corpus1 <- tm_map(corpus1, removeWords, stopwords("English")) ## inspect your stopword lists
corpus1 <- tm_map(corpus1, content_transformer(removePunctuation))
# corpus1 <- tm_map(corpus1, stemDocument, language = "english") # stem your words
#create your document term matrix
corpus1.dtm<-DocumentTermMatrix(corpus1, control=list(wordLengths=c(1,Inf)))
corpus1.matrix<-as.matrix(corpus1.dtm, stringsAsFactors=F)
#perform transformations on the raw counts
#Remove sparse terms
corpus1.dtm.sparse<-removeSparseTerms(corpus1.dtm, 0.4) #lower number = requiring that a word be in more documents
corpus1.matrix.sparse<-as.matrix(corpus1.dtm.sparse, stringsAsFactors=F)
#Scale your data
scaling1<-rowSums(corpus1.matrix) #get total word counts for each work
corpus1.scaled<-corpus1.matrix.sparse/scaling1
label.df<-data.frame(row.names(corpus1.scaled))
colnames(label.df)<-c("filenames")
label.df<-cSplit(label.df, 'filenames', sep="_", type.convert=FALSE)
corpus1.scaled<-data.frame(corpus1.scaled)
corpus1.scaled$corpus<-label.df$filenames_1
df<-corpus1.scaled
#Step 2: Run classification test using SVM learning algorithm
#first create folds
folds<-createFolds(df$corpus, k=5)
label.df<-data.frame(row.names(corpus1.scaled))
colnames(label.df)<-c("filenames")
label.df<-cSplit(label.df, 'filenames', sep="_", type.convert=FALSE)
corpus1.scaled<-data.frame(corpus1.scaled)
corpus1.scaled$corpus<-label.df$filenames_1
df<-corpus1.scaled
library("splitstackshape")
label.df<-data.frame(row.names(corpus1.scaled))
colnames(label.df)<-c("filenames")
label.df<-cSplit(label.df, 'filenames', sep="_", type.convert=FALSE)
corpus1.scaled<-data.frame(corpus1.scaled)
corpus1.scaled$corpus<-label.df$filenames_1
df<-corpus1.scaled
folds<-createFolds(df$corpus, k=5) # k = number of folds (1-10) where 10 is best
install.packages("rworldmap")
d <- data.frame(
country=c("Greece", "France", "Germany", "Italy", "Norway"),
value=c(-2, -1, 0, 1, 2))
mapCountryData(n, nameColumnToPlot="value", mapTitle="World")
library(rworldmap)
d <- data.frame(
country=c("Greece", "France", "Germany", "Italy", "Norway"),
value=c(-2, -1, 0, 1, 2))
mapCountryData(n, nameColumnToPlot="value", mapTitle="World")
d <- data.frame(
country=c("Greece", "France", "Germany", "Italy", "Norway"),
value=c(-2, -1, 0, 1, 2))
mapCountryData(d, nameColumnToPlot="value", mapTitle="World")
View(d)
mapCountryData(d, nameColumnToPlot="value", mapTitle="World")
n <- joinCountryData2Map(d, joinCode="NAME", nameJoinColumn="country")
mapCountryData(d, nameColumnToPlot="value", mapTitle="World")
mapCountryData(n, nameColumnToPlot="value", mapTitle="World")
#bring in the data
met <- as.data.frame(read.csv("MetObjects_5k-sample.csv"))
tate <- as.data.frame(read.csv("TateObjects_5k-sample.csv"))
setwd("~/GitHub/springboard/3. Maps with R and ggmaps")
met <- as.data.frame(read.csv("MetObjects_5k-sample.csv"))
tate <- as.data.frame(read.csv("TateObjects_5k-sample.csv"))
View(met)
countries.met <- table(met$Country)
countries.met <- as.data.frame(table(met$Country))
View(countries.met)
View(tate)
n <- joinCountryData2Map(countries.met, joinCode="NAME", nameJoinColumn="country")
countries.met <- as.data.frame(table(met$Country))
View(countries.met)
colnames(countries.met) <- c("country", "value")
n <- joinCountryData2Map(countries.met, joinCode="NAME", nameJoinColumn="country")
mapCountryData(n, nameColumnToPlot="value", mapTitle="World")
mapCountryData(n, nameColumnToPlot="value", mapTitle="World", catMethod = "pretty")
countries.met <- as.data.frame(table(met$Country))
colnames(countries.met) <- c("country", "value")
matched <- joinCountryData2Map(countries.met, joinCode="NAME", nameJoinColumn="country")
mapCountryData(matched, nameColumnToPlot="value", mapTitle="Met Collection Country Sample", catMethod = "pretty")
View(met)
View(countries.met)
countries.met <- countries.met[-21]
View(countries.met)
countries.met <- countries.met[-21,]
View(countries.met)
matched <- joinCountryData2Map(countries.met, joinCode="NAME", nameJoinColumn="country")
mapCountryData(matched, nameColumnToPlot="value", mapTitle="Met Collection Country Sample", catMethod = "pretty")
View(countries.met)
mapCountryData(matched, nameColumnToPlot="value", mapTitle="Eurasia",
mapRegion="Eurasia", colourPalette="terrain")
mapCountryData(matched, nameColumnToPlot="value", mapTitle="Eurasia",
mapRegion="Eurasia", colourPalette="terrain", catMethod="pretty")
colnames(nationality.met) <- c("country", "value")
nationality.met <- as.data.frame(table(met$Artist.Nationality))
colnames(nationality.met) <- c("country", "value")
View(nationality.met)
matched.nationality <- joinCountryData2Map(nationality.met, joinCode="NAME", nameJoinColumn="country")
mapCountryData(matched, nameColumnToPlot="value", mapTitle="Met Collection Country Sample", catMethod = "pretty", colourPalette = "topo")
mapCountryData(matched, nameColumnToPlot="value", mapTitle="Met Collection Country Sample", catMethod = "pretty", colourPalette = "heat")
moma <- as.data.frame(read.csv("~/Data/Art/MoMA/Artworks.csv"))
head(moma)
View(moma)
View(countries.met)
mapCountryData(matched, nameColumnToPlot="value", mapTitle="Met Collection Country Sample", catMethod = "pretty", colourPalette = "heat")
library(rworldmap)
#bring in the data
met <- as.data.frame(read.csv("MetObjects_5k-sample.csv"))
#country of origin frequency table
countries.met <- as.data.frame(table(met$Country))
colnames(countries.met) <- c("country", "value")
#optional -- delete egypt b/c of skew
matched <- joinCountryData2Map(countries.met, joinCode="NAME", nameJoinColumn="country")
mapCountryData(matched, nameColumnToPlot="value", mapTitle="Met Collection Country Sample", catMethod = "pretty", colourPalette = "heat")
countries.met.2 <- countries.met[-21,]
matched.2 <- joinCountryData2Map(countries.met.2, joinCode="NAME", nameJoinColumn="country")
mapCountryData(matched.2, nameColumnToPlot="value", mapTitle="Met Collection Country Sample", catMethod = "pretty", colourPalette = "diverging")
mapCountryData(matched.2, nameColumnToPlot="value", mapTitle="Met Collection Country Sample", catMethod = "pretty", colourPalette = "heat")
View(countries.met.2)
mapCountryData(matched, nameColumnToPlot="value", mapTitle="Eurasia", mapRegion="Eurasia", colourPalette="terrain", catMethod="pretty")
mapCountryData(matched, nameColumnToPlot="value", mapTitle="Eurasia", mapRegion="Eurasia", colourPalette="heat", catMethod="pretty")
mapCountryData(matched.2, nameColumnToPlot="value", mapTitle="Eurasia", mapRegion="Eurasia", colourPalette="heat", catMethod="pretty")
mapCountryData(matched.2, nameColumnToPlot="value", mapTitle="Met Collection in Eurasia", mapRegion="Eurasia", colourPalette="heat", catMethod="pretty")
library("kernlab")
library("caret")
library("tm")
library("dplyr")
library("splitstackshape")
corpus1 <- tm_map(corpus1, content_transformer(stripWhitespace), content_transformer(tolower))
setwd("~/GitHub/springboard/4. Machine Learning with R")
train <- VCorpus(DirSource("Train", encoding = "UTF-8"), readerControl=list(language="English"))
train <- VCorpus(DirSource("Training", encoding = "UTF-8"), readerControl=list(language="English"))
corpus1 <- tm_map(corpus1, content_transformer(stripWhitespace), content_transformer(tolower))
train <- tm_map(train, content_transformer(stripWhitespace), content_transformer(tolower))
train <- tm_map(train, content_transformer(stripWhitespace))
train <- tm_map(train, content_transformer(stripWhitespace))
library("kernlab")
library("caret")
library("tm")
library("dplyr")
library("splitstackshape")
train <- tm_map(train, content_transformer(stripWhitespace))
train <- tm_map(train, content_transformer(stripWhitespace), mc.cores=1)
train <- VCorpus(DirSource("Training", encoding = "UTF-8"), readerControl=list(language="English"))
train <- tm_map(train, content_transformer(stripWhitespace), mc.cores=1)
train <- tm_map(train, content_transformer(stripWhitespace))
corpus1 <- tm_map(corpus1, content_transformer(tolower))
train <- VCorpus(DirSource("Training", encoding = "UTF-8"), readerControl=list(language="English"))
train <- tm_map(train, content_transformer(stripWhitespace))
train <- tm_map(train, content_transformer(tolower))
train <- tm_map(train, content_transformer(removeNumbers))
train <- tm_map(train, removeWords, stopwords("English")) ## inspect your stopword lists
train <- tm_map(train, content_transformer(removePunctuation))
train <- tm_map(train, stemDocument, language = "english") # stem your words
train.dtm<-DocumentTermMatrix(train, control=list(wordLengths=c(1,Inf)))
train.matrix<-as.matrix(train.dtm, stringsAsFactors=F)
train <- VCorpus(DirSource("Training", encoding = "UTF-8"), readerControl=list(language="English"))
train <- tm_map(train, content_transformer(stripWhitespace))
train <- tm_map(train, content_transformer(tolower))
train <- tm_map(train, content_transformer(removeNumbers))
train <- tm_map(train, content_transformer(removePunctuation))
train.dtm<-DocumentTermMatrix(train, control=list(wordLengths=c(1,Inf)))
train.matrix<-as.matrix(train.dtm, stringsAsFactors=F)
train.dtm <- as.matrix(DocumentTermMatrix(train, control=list(wordLengths=c(1,Inf))))
View(train.dtm)
test <- VCorpus(DirSource("Test", encoding = "UTF-8"), readerControl=list(language="English"))
test <- tm_map(test, content_transformer(stripWhitespace))
test <- tm_map(test, content_transformer(tolower))
test <- tm_map(test, content_transformer(removeNumbers))
test <- tm_map(test, content_transformer(removePunctuation))
test.dtm <- as.matrix(DocumentTermMatrix(test, control=list(wordLengths=c(1,Inf))))
train.df <- data.frame(train.dtm[,intersect(colnames(train.dtm), colnames(test.dtm))])
test.df <- data.frame(test.dtm[,intersect(colnames(test.dtm), colnames(train.dtm))])
label.df<-data.frame(row.names(train.df))
colnames(label.df)<-c("filenames")
label.df<-cSplit(label.df, 'filenames', sep="_", type.convert=FALSE)
train.df$corpus<- label.df$filenames
test.df$corpus <- c("Pos")
x <- folds$Fold01 #use this line of k = 10
df.train <- train.df
df.test <- train.df
df.model<-ksvm(corpus ~ ., data=df.train, kernel="rbfdot")
df.pred<-predict(df.model, df.test)
con.matrix<-confusionMatrix(df.pred, df.test$corpus)
folds<- createFolds(train.df$corpus, k=10)
x<-folds$Fold01
df.train<- c1.df
df.test<-c1.df
df.model<-ksvm(corpus ~ ., data=df.train, kernel="rbfdot")
folds<- createFolds(train.df$corpus, k=10)
x<-folds$Fold01
df.train<- train.df
df.test<-train.df
df.model<-ksvm(corpus ~ ., data=df.train, kernel="rbfdot")
label.df<-data.frame(row.names(train.df))
colnames(label.df)<-c("filenames")
label.df<-cSplit(label.df, 'filenames', sep="_", type.convert=FALSE)
train.df$corpus<- label.df$filenames
test.df$corpus <- c("Pos")
df.model<-ksvm(corpus ~ ., data=df.train, kernel="rbfdot")
folds<- createFolds(train.df$corpus, k=10)
View(df.train)
df.model<-ksvm(corpus ~ ., data=df.train, kernel="rbfdot")
df.model<-ksvm(corpus ~., data= df.train, kernel="rbfdot")
View(df.train)
print(df.train$corpus)
label.df <- data.frame(row.names(train.df))
View(label.df)
colnames(label.df) <- c("filenames")
View(label.df)
label.df<- cSplit(label.df, 'filenames', sep="_", type.convert=FALSE)
View(label.df)
View(label.df)
train.df$corpus<- label.df$filenames_1
test.df$corpus <- c("Pos")
df.train <- train.df
df.test <-train.df
df.model<-ksvm(corpus~., data= df.train, kernel="rbfdot")
df.pred<-predict(df.model, df.test)
con.matrix<-confusionMatrix(df.pred, df.test$corpus)
print(con.matrix)
test.df$corpus <- c("Neg")
folds<- createFolds(train.df$corpus, k=10)
x <-folds$Fold01
df.train <- train.df
df.test <- train.df
df.model<-ksvm(corpus~., data= df.train, kernel="rbfdot")
df.pred<-predict(df.model, df.test)
con.matrix<-confusionMatrix(df.pred, df.test$corpus)
print(con.matrix)
# Step 1. Ingest your training data and clean it.
train <- VCorpus(DirSource("Training", encoding = "UTF-8"), readerControl=list(language="English"))
train <- tm_map(train, content_transformer(stripWhitespace))
train <- tm_map(train, content_transformer(tolower))
train <- tm_map(train, content_transformer(removeNumbers))
train <- tm_map(train, content_transformer(removePunctuation))
# Step 2. Create your document term matrices for the training data.
train.dtm <- as.matrix(DocumentTermMatrix(train, control=list(wordLengths=c(1,Inf))))
#train.matrix <- as.matrix(train.dtm, stringsAsFactors=F)
# Step 3. Repeat steps 1 & 2 above for the Test set.
test <- VCorpus(DirSource("Test", encoding = "UTF-8"), readerControl=list(language="English"))
test <- tm_map(test, content_transformer(stripWhitespace))
test <- tm_map(test, content_transformer(tolower))
test <- tm_map(test, content_transformer(removeNumbers))
test <- tm_map(test, content_transformer(removePunctuation))
test.dtm <- as.matrix(DocumentTermMatrix(test, control=list(wordLengths=c(1,Inf))))
# Step 4. Make test and train matrices of identical length (find intersection)
train.df <- data.frame(train.dtm[,intersect(colnames(train.dtm), colnames(test.dtm))])
test.df <- data.frame(test.dtm[,intersect(colnames(test.dtm), colnames(train.dtm))])
# Step 5. Retrieve the correct labels for training data and put dummy values for testing data
label.df <- data.frame(row.names(train.df))
colnames(label.df) <- c("filenames")
label.df<- cSplit(label.df, 'filenames', sep="_", type.convert=FALSE)
train.df$corpus<- label.df$filenames_1
test.df$corpus <- c("Neg")
df.train <- train.df
df.test <- train.df
df.model<-ksvm(corpus~., data= df.train, kernel="rbfdot")
df.pred<-predict(df.model, df.test)
con.matrix<-confusionMatrix(df.pred, df.test$corpus)
print(con.matrix)
df.train <- train.df
df.test <- test.df
df.model<-ksvm(corpus~., data= df.train, kernel="rbfdot")
df.pred<-predict(df.model, df.test)
print(df.pred)
results <- as.data.frame(df.pred)
rownames(results) <- rownames(test.df)
print(results)
